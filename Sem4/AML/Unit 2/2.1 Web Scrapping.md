Web scrapping is the process of extracting data from websites using a script or program. It involves going through the HTML code and extracting the desired information then storing and using the information.

## Ways to Scrap

1) Manually : Manually going through the webpage's code and copying the desired info by hand. Good for simple one time information gathering.
2) Regular Expression: Using regex to find patterns and extract them. Effective but gets complex as HTML's structure gets 
3) Beautiful Soup: Python library for web scraping. Provides API to navigate through HTML and XML documents and get data. Does this via creating a parse tree, which allows for easier location of desired elements.
4) Scrapy: Powerful python framework for web scraping. Grants more features like: asynchronous requests, pagination, complex website handling etc. It is scalable too.
5) Selenium: Automating tool that is useful when dealing with JS heavy websites. Can control the browser and can extract data from dynamically generated content. 
6) API: Application Programming Interfaces are sometimes provided by websites that allow Devs to access content in a structured format like JSON or XML etc. No need to parsing through HTML code.  
7) Headless Browser: Automate web scraping by running a browser in background without GUI, allows us to execute JS and extract data programmatically.


> Links 
[[2.1.1 Beautiful Soup]]
[[2.1.2 Regular Expression]]

