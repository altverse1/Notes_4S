Set of techniques to transform raw data into a form that is suitable for the machine learning algorithms. 

Steps for data transformation: 
- Data Cleaning - This step involves removing any missing data or inconsistent records. 
- Data Scaling - To bring data into a common range to avoid numerical instability.
- Data Encoding - Converting categorical data into numeric data using encoders.
- Feature Selection - Selecting most relevant features using PCA/ correction analysis.
- Feature Engineering - Creating new features using existing data. 

## Pipeline - Data Transformer

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler,OneHotEncoder, PolynomialFeatures
from sklearn.feature_selection import SelectKBest, f_classification

#defining the pipeline
pipeline = Pipeline([('scaler', StandardScaler()),
					('encoder', OneHotEncoder()),
					('selector', SelectKBest(score_fun=f_classif, k=10))
					('poly',PolynomialFeature(degrees=2))
				   ])
#fitting 
x_train_transformed = pipeline.fit_transform(x_train, y_train)

#for new data
x_test_transformed = pipeline.transform(x_test)

```

The above pipeline includes four transformers: 
1. Standard Scaler
2. One Hot Encoder
3. Select K Best 
	Select top k features based on the F value between feature and target variable.
4. Polynomial Features 
	Is used to create polynomial features up to degree 2.



