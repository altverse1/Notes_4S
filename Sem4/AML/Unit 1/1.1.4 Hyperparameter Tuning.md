Process of selecting the best hyperparameters for ML model to improve the performance is called Model Tuning.

**Hyperparameter** - Parameters that the user sets before the training of the model.

%%
In the context of the `SVC` model, the `kernel` parameter is a hyperparameter because it is set by the user before training and is not updated or learned during the training process. The kernel type (e.g., `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'`) is chosen based on prior knowledge or assumptions about the data and the problem at hand.

Learned parameters in the `SVC` model, on the other hand, include the support vectors, coefficients, and bias term, which are adjusted during training to find the optimal decision boundary for the classification task. 
%%

## Grid Search CV
It involves searching through each possibility in a specified `grid of hyperparameters` for a given model. It then selects the best hyperparameters that produce the best performance based on a specific scoring metric.

```python
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris

iris = load_iris()
x = iris.data
y = iris.target

dtc = DecisionTreeClassifier()

param_grid = {'criterion':['gini','entropy'],
			  'max_depth':[3,4,5,6],
			  'min_samples_split':[2,3,4,5],
			  'min_samples_leaf':[1,2,3,4]
			 }
grid_search = GridSearchCV(dtc, param_grid, cv=5, scoring='accuracy')
grid_search.fit(x,y)

print("Best HyperParameters: ", grid_search.best_params_)
print("Best Acc Score: ", grid_search.best_score_)
```


## Randomized Search CV
- Why this over grid search? 
	Grid Search cv is computationally expensive for a large set of hyperparameters(results in too many combinations). 

Here instead of all combinations of hyperparameters we go through a user set number of iterations and in the process goes over a random set of hyperparameters.

This gives the user more control over computational budget over hyperparameter searching. 

```python
from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import RandomForestClassifier
from sklearn.datasets import load_iris

iris = load_iris()
x = iris.data
y = iris.target

rfc = RandomForestClassifier()

param_distribution = {'n_estimators': [100,200,300,400,500],
			'max_depth': [3,5,7,9,11,13,15,None],
			'min_samples_split':[2,3,4,5,6,7,8,9,10],
			'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10],
			'bootstrap':[True, False],
			'criterion':['gini','entropy']
			 }

random_search = RandomizedSearchCV(rfc, param_distributions = param_distribution, n_iter=100, cv=5, scoring = 'accuracy', random_state=42)
random_search.fit(x,y)
print("Best HyperParameters: ", grid_search.best_params_)
print("Best Acc Score: ", grid_search.best_score_)
```


